{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Proyecto de Máquinas de Aprendizaje - ILI393\n",
    "## _Identificación facial cuando existen pocos ejemplos por clase_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema consiste en la correcta identificación y reconocimiento facial, dado el caso particular en donde existen muy pocos ejemplos por clase (por persona) para entrenar los algoritmos algoritmos de clasificación. La mayoría de los enfoques usados en este tipo de problemas consisten en encontrar una buena representación de las características importantes de las caras, para posteriormente realizar algún tipo de búsqueda (jerárquica, nearest neighbors, etc). Sin embargo se propone aquí resolver el problema con tres algoritmos de clasificación distintos: Linear Discriminant Analysis, Support Vector Machines (con kernel lineal y radio basal) y por Convolutional Neural Networks.\n",
    "\n",
    "Los dataset a ocupar son [Faces94](http://cswww.essex.ac.uk/mv/allfaces/faces94.html), [Faces95](http://cswww.essex.ac.uk/mv/allfaces/faces95.html) y [Faces96](http://cswww.essex.ac.uk/mv/allfaces/faces96.html). Cada uno de los datasets consiste en 20 imágenes de individuos, y variable cantidad de individuos. Los datasets están ordenados en cuanto a su complejidad de reconocimiento de menor a mayor. Se muestran a continuación imágenes representativas de Faces94, Faces95 y Faces96 respectivamente.\n",
    "\n",
    "<img src=\"faces94ex.jpg\">\n",
    "\n",
    "<img src=\"faces95ex.jpg\">\n",
    "\n",
    "<img src=\"faces96ex.jpg\">\n",
    "\n",
    "Para cada uno de estos datasets, se crearon training y testing sets correspondientes. La metodología fue la siguiente: Para cada dataset (94,95,96) se tomaron aleatoriamente entre 2-5 fotos por clase (por persona) para formar los training sets correspondientes, y las restantes 15-18 fotos se dejaron para crear los testing sets correspondientes. Vale decir, si se entrena con train94/5pc (faces94, 5 samples per class) entonces se prueba con test94/15pc (faces94, 15 samples per class). Cumpliendo de este modo con la restricción de tener pocos samples para entrenar los algoritmos.\n",
    "\n",
    "**Observación**: Por el momento se trabaja sólo con Faces94 y Faces95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 1: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación ocupada corresponde la de Scikit-Learn. Para cada una de las clases (personas) genera la función discriminante lineal $\\delta_k$, que permite diferenciar a cada una de las clases. Los dos supuestos fuertes que se realizan sobre los datasets al ocupar este método, son que 1) La probabilidad multivariada de las características $P(x_m | y=k)$ se distribuye normal, y que 2) La matriz de covarianza para cada una de las clases es igual.\n",
    "\n",
    "Debido a que LDA es un modelo generativo sin _hiperparámetros_, es que no es necesario realizar cross-validation para el modelo. Esto es una gran ventaja, pues ahora gran tiempo de computación (comparado con los otros métodos). Sin embargo, como se verá más adelante, paga este costo de simplicidad, entregando resultados menos precisos y generalizantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LDA con Faces94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: './db/test94/ts-2pc-0/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-51f567b8fc97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msolve_lda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'faces94'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-b8e77b5960ff>\u001b[0m in \u001b[0;36msolve_lda\u001b[1;34m(dataset, spc)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#loading training and testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspc_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspc_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mX_ts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspc_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspc_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m#creating LDA object and fitting the testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-12f1ecabb64f>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path, spc, stacked)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#total number of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m#dimensions of each image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: './db/test94/ts-2pc-0/'"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    solve_lda('faces94',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ De las matrices de confusión, se nota que el dataset Faces94 es muy \"fácil\" y por lo tanto los resultados son casi perfectos. Si se ven las imágenes en este, se pude notar que todas son muy parecidas entre ellas, vale decir, hay poca variación en la pose, expresión, iluminación, etc. Por lo cual esta data es fácilmente separable por hiperplanos.\n",
    "+ De todos modos, a medida que aumentan las muestras por clase, el error rate tiende a disminuir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA con Faces95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    solve_lda('faces95',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ Se nota claramente que el dataset Faces95 es un dataset mucho más complejo que el anterior.\n",
    "+ Los error rates son claramente mayores, siendo estos muy altos para los casos en donde hay pocos ejemplos por clase.\n",
    "+ De todas maneras el comportamiento tiende a mejorar cuando existen más muestras por clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 2: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enfoque seguido en esta sección, es la implementación y entrenamiento de multiclass SVM's con kernels tanto lineales como gaussianos, para cumplir con el objetivo de clasificar la data. Debido a que los datasets fueron generados de manera balanceada en cuanto a las clases, se utilizan _C-SVM's_. La implementación ocupada corresponde a la de Scikit-Learn, la cual advierte: _“SVC  implement one-against-one” approach (Knerr et al., 1990) for multi- class classification.\"_\n",
    "\n",
    "Para la selección de _hiperparámetros_ $C$ y $\\gamma$ (en kernels rbf) se realiza 5-fold cross validation sobre cada training set, con la ayuda de grid search.\n",
    "\n",
    "Debido a que las dimensiones de las imágenes (200x180=36000) corresponden al total de features de cada foto, se ha decidido realizar una reducción de dimensionalidad para mejorar los tiempos de entrenamientos y eficiencia, así como también tomar las características realmente importantes (aquellas que permiten diferencias entre las clases).\n",
    "\n",
    "Como técnica de reducción de dimensionalidad, se ha decidido ocupar LDA como reducción de dimensionalidad supervisada, representación tambien conocida como [_Fisher Faces_](http://www.scholarpedia.org/article/Fisherfaces). Esta técnica\n",
    "intenta encontrar un subespacio donde proyectar la data que permita diferenciar de mejor manera las clases. Dicho de otro modo, se intenta maximizar la **inter-class variance**  y minimizar la varianza **intra-class variance**.\n",
    "\n",
    "Básicamente los hiperplanos que conforman el subespacio de representación, corresponden a la funciones discriminantes que genera el modelo en LDA. La idea se plasma en la siguiente representación\n",
    "\n",
    "<img src=\"lineardisc.jpg\">\n",
    "\n",
    "en donde cada dato se proyecta en los hiperplanos discriminantes, para formar la representación. El número de máximo de discriminantes es $\\min(\\text{dimensiones},\\text{clases}-1)$, por lo tanto en un problema con muchas más dimensiones (features) que clases, la reducción de dimensionalidad es mayor (este problema es precisamente el caso). Se pueden ocupar menos discriminantes, pero para los experimentos que se muestran a continuación se ocupan todos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "+ Los rangos de los parámetros fueron determinados empíricamente, probando aquellos que entregan resultados coherentes y útiles en los datasets respectivos.\n",
    "+ Los scores que se muestran, corresponden a la precisión o tasa de acierto (contrario al error rate). Valores más cercanos a 1 son deseables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting parameters to try on Linear-SVM for Faces94 and Faces95\n",
    "C1 = np.linspace(1e-3, 1e-2, 20, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-SVM con Faces94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spc in range(2,6):\n",
    "    solve_svm('faces94', spc, 'linear', C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ Sucede lo mismo que con LDA: Faces94 es muy fácil de separar por hiperplanos y por lo tanto obtiene muy buen resultado también la SVM con kernel lineal.\n",
    "+ Los error rates obtenidos aquí son ligeramente inferiores a los obtenidos con LDA.\n",
    "+ Sigue el patrón de mejorar los resultados a medida que aumentan las muestras por clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-SVM con Faces95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spc in range(2,6):\n",
    "    solve_svm('faces95', spc, 'linear', C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ Los resultados aquí obtenidos, mejoran en una cantidad notoria respecto a el mismo dataset aplicado con LDA. Sin embargo, no hay que olvidar que aquí se tuvo que realizar un proceso de cross-validation para establecer _hiperparámetros_ y en LDA no.\n",
    "+ Se mantiene el patrón de mejorar los resultados a medida que aumentan los ejemplos por clase.\n",
    "+ Notar que los resultados obtenidos para pocos ejemplos por clase (2-3) son peores que los que obtiene LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Kernel-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "+ Los rangos de los parámetros fueron determinados empíricamente, probando aquellos que entregan resultados coherentes y útiles en los datasets respectivos.\n",
    "+ Los scores que se muestran, corresponden a la precisión o tasa de acierto (contrario al error rate). Valores más cercanos a 1 son deseables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters to try one kernel-svm\n",
    "C2 = np.linspace(1e+0, 1e+1, 6, endpoint=True)\n",
    "Gamma = np.linspace(1e-3, 1e-2, 6, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kernel-SVM con Faces94 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spc in range(2,6):\n",
    "    solve_svm('faces94', spc, 'rbf', C2, Gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ Los resultados obtenidos son similares a los anteriores. Como se vio anteriormente, este dataset es muy fácilmente separable por hiperplanos. El hecho de que con kernels rbf pueda aprender fronteras de decisión más complejas por lo tanto no está ayudando mucho.\n",
    "+ Extrañamente el error rate aumenta en el caso de 5 ejemplos por clase.\n",
    "+ Los resultados podrían mejorar aún más si se realiza las selección de _hiperparámetros_ en una malla más fina, pero esto requeriría de mucho tiempo de computación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel-SVM con Faces95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spc in range(2,6):\n",
    "    solve_svm('faces95', spc, 'rbf', C2, Gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:**\n",
    "+ Los resultados obtenidos para 4-5 ejemplos por clase no son muy distintos a los de los enfoques anteriores sobre este mismo dataset. Sin embargo para 2-3 ejemplos por clases, tiene un muy buen resultado respecto de los otros enfoques.\n",
    "+ Los resultados podrían mejorar aún más si se realiza las selección de _hiperparámetros_ en una malla más fina, pero esto requeriría de mucho tiempo de computación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 3: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anexo de Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "> function to load data from path directory to a matrix.\n",
    "> each row of the resulting matrix, corresponds to a flattened image\n",
    "  in grayscale format\n",
    "\"\"\"\n",
    "def load_data(path, spc, stacked=False):\n",
    "    #total number of classes\n",
    "    M = len(os.listdir(path))\n",
    "    #dimensions of each image\n",
    "    N = 200*180\n",
    "    #matrix with features\n",
    "    if stacked:\n",
    "        data = np.empty((M*spc,1,200,180))\n",
    "    else: \n",
    "        data = np.empty((M*spc,N))\n",
    "    labels = np.empty(M*spc)\n",
    "    #index of data matrix\n",
    "    m = 0\n",
    "    for i in range(1,M+1):\n",
    "        tgt = path+str(i)+'/'\n",
    "        pics = os.listdir(tgt)\n",
    "        for pic in pics:\n",
    "            if stacked:\n",
    "                #store each image, as a bidimensional array in data matrix\n",
    "                data[m,0,:,:] = cv.imread(tgt+pic, cv.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                #store each flattened image, as a row in data matrix\n",
    "                data[m,:] = cv.imread(tgt+pic, cv.IMREAD_GRAYSCALE).ravel()\n",
    "            labels[m] = i\n",
    "            m += 1\n",
    "    return (data.astype(np.float32), labels.astype(np.uint8))\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"\n",
    "This is just a simple helper function iterating over training data in\n",
    "mini-batches of a particular size, optionally in random order. It assumes\n",
    "data is available as numpy arrays. For big datasets, you could load numpy\n",
    "arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "own custom data iteration function. For small datasets, you can also copy\n",
    "them to GPU at once for slightly improved performance. This would involve\n",
    "several changes in the main program, though, and is not demonstrated here.\n",
    "\"\"\"\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    M = inputs.shape[0]\n",
    "    num_batches = M/batchsize\n",
    "    if shuffle:\n",
    "        indices = np.arange(M)\n",
    "        np.random.shuffle(indices)\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx*batchsize\n",
    "        if batch_idx==num_batches-1: end_idx = M\n",
    "        else: end_idx = start_idx+batchsize\n",
    "        if shuffle: \n",
    "            excerpt = indices[start_idx:end_idx]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, end_idx)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_ts, y_pd):\n",
    "    #true positives\n",
    "    tp = (y_ts==y_pd).sum()\n",
    "    #total of predictions\n",
    "    n = y_ts.shape[0]\n",
    "    return tp/np.float(n)\n",
    "\n",
    "def error_rate(y_ts, y_pd):\n",
    "    return 1-precision(y_ts, y_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solve_lda(dataset, spc):\n",
    "    #samples per class on training set\n",
    "    spc_tr = spc\n",
    "    spc_ts = 20-spc_tr\n",
    "    #training and testing paths\n",
    "    tr_path = './db/train'+dataset[-2:]+'/tr-{0}pc-{1}/'\n",
    "    ts_path = './db/test'+dataset[-2:]+'/ts-{0}pc-{1}/'\n",
    "    \n",
    "    #iterating through datasets\n",
    "    for set_num in range(20):\n",
    "        #loading training and testing set\n",
    "        X_tr,y_tr = load_data(tr_path.format(spc_tr,set_num), spc_tr)\n",
    "        X_ts,y_ts = load_data(ts_path.format(spc_ts,set_num), spc_ts)\n",
    "        #creating LDA object and fitting the testing data\n",
    "        clf = LDA()\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        #making predictions\n",
    "        y_pd = clf.predict(X_ts)\n",
    "\n",
    "        print \"#####################################################################################\"\n",
    "        print \"Dataset {0}: {1} samples per class\".format(dataset,spc)\n",
    "        #computing the confussion matrix and plotting results\n",
    "        print \"Error rate: {0}\".format(error_rate(y_ts,y_pd))\n",
    "        cm = confusion_matrix(y_ts, y_pd)\n",
    "        plot_confusion_matrix(cm)\n",
    "        print \"#####################################################################################\"\n",
    "        #releasing memory of big objects\n",
    "        del X_tr, X_ts, clf, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Supervised dimensionality reduction through LDA\n",
    "\"\"\"\n",
    "def fisher_faces(X, y):\n",
    "    #supervised learning through LDA\n",
    "    #finding the discriminant functions\n",
    "    ff = LDA()\n",
    "    ff.fit(X,y)\n",
    "    #proyect the data into linear discriminant hyperplanes\n",
    "    return ff\n",
    "\n",
    "\"\"\"\n",
    "5-fold cross validation y Grid search\n",
    "para determinar el mejor parametro C en\n",
    "linear svm\n",
    "\"\"\"\n",
    "def cross_linear_svm(X, y, C):\n",
    "    #generating 5-folds\n",
    "    M,_ = X.shape\n",
    "    kf = KFold(M, n_folds=5)\n",
    "    #parameters to try\n",
    "    params = {'C':C}\n",
    "    #Setting grid search for linear-svm and 5-fold cross validation\n",
    "    svc = svm.SVC(kernel='linear')\n",
    "    clf = grid_search.GridSearchCV(svc, params, cv=kf, n_jobs=4)\n",
    "    #make it\n",
    "    clf.fit(X, y)\n",
    "    #return best parameters and grid scores\n",
    "    return clf.best_params_['C'] , clf.grid_scores_\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5-fold cross validation y Grid search\n",
    "para determinar el mejor parametro C y\n",
    "gamma en rbf svm\n",
    "\"\"\"\n",
    "def cross_rbf_svm(X, y, C, Gamma):\n",
    "    #generating 5-folds\n",
    "    M,_ = X.shape\n",
    "    kf = KFold(M, n_folds=5)\n",
    "    #parameters to try\n",
    "    params = {'C':C, 'gamma':Gamma}\n",
    "    #Setting grid search for rbf-svm and 5-fold cross validation\n",
    "    svc = svm.SVC(kernel='rbf')\n",
    "    clf = grid_search.GridSearchCV(svc, params, cv=kf, n_jobs=4)\n",
    "    #make it\n",
    "    clf.fit(X, y)\n",
    "    #return best parameters and grid scores\n",
    "    return clf.best_params_['C'], clf.best_params_['gamma'] , clf.grid_scores_\n",
    "\n",
    "\n",
    "def solve_svm(dataset, spc, kernel, C, Gamma=None):\n",
    "    #samples per class on training set\n",
    "    spc_tr = spc\n",
    "    spc_ts = 20-spc_tr\n",
    "    #loading training and testing set\n",
    "    X_tr,y_tr = load_data('./db/train'+dataset[-2:]+'/', spc_tr)\n",
    "    X_ts,y_ts = load_data('./db/test'+dataset[-2:]+'/', spc_ts)\n",
    "    #projecting into discriminant space\n",
    "    ff = fisher_faces(X_tr, y_tr)\n",
    "    X_tr = ff.transform(X_tr)\n",
    "    X_ts = ff.transform(X_ts)\n",
    "    #choosing best C (and gamma) through 5-fold cross-validation and grid search\n",
    "    if kernel=='linear':\n",
    "        c,grid_scores = cross_linear_svm(X_tr, y_tr, C)\n",
    "    elif kernel=='rbf':\n",
    "        c,gamma,grid_scores = cross_rbf_svm(X_tr, y_tr, C, Gamma)\n",
    "    #fitting the model\n",
    "    if kernel=='linear':\n",
    "        clf = SVC(kernel='linear', C=c)\n",
    "    elif kernel=='rbf':\n",
    "        clf = SVC(kernel='rbf', C=c, gamma=gamma)    \n",
    "    clf.fit(X_tr,y_tr)\n",
    "    #making predictions\n",
    "    y_pd = clf.predict(X_ts)\n",
    "    print \"#####################################################################################\"\n",
    "    print \"Dataset {0}: {1} samples per class\".format(dataset,spc)\n",
    "    print \"Error rate: {0}\".format(error_rate(y_ts, y_pd))\n",
    "    print \"Best C: {0}\".format(c)\n",
    "    if kernel=='rbf':\n",
    "        print \"Best gamma: {0}\".format(gamma)\n",
    "    print \"Grid scores:\"\n",
    "    for i in range(len(grid_scores)):\n",
    "        print grid_scores[i]\n",
    "    #computing the confussion matrix and plotting results\n",
    "    cm = confusion_matrix(y_ts, y_pd)\n",
    "    plot_confusion_matrix(cm)\n",
    "    print \"#####################################################################################\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
