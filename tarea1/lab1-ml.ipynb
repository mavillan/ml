{
 "metadata": {
  "name": "",
  "signature": "sha256:d48786ecac2de6b5843ffbf488bb38678a887b1dd9e22e6c72cd4b2a8875ef0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parte 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#notebook settings\n",
      "%matplotlib inline\n",
      "\n",
      "#import some useful libraries\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#setting some paths\n",
      "path1='./cereales/'\n",
      "path2='./credit/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#overall cost function\n",
      "def J(M, beta):\n",
      "    X = M[:,:-1]\n",
      "    y = M[:,-1]\n",
      "    h = np.dot(X,beta)\n",
      "    return np.sum((h-y)**2)\n",
      "\n",
      "#Implementation of batch gradient descent (vectorized!)\n",
      "def gd_batch(M, alpha=0.5, n_iter=50, mode=None):\n",
      "    X = M[:,:-1]\n",
      "    y = M[:,-1]\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 10 iterations\n",
      "            if k%10==0: print \"Iter:\",k,\" Cost:\",J(M, beta)\n",
      "        h = np.dot(X,beta)\n",
      "        dJ = np.dot(X.transpose(),h-y)\n",
      "        beta -= (alpha/m)*dJ\n",
      "    return beta\n",
      "\n",
      "#Implementation of online gradient descent\n",
      "def gd_online(M, alpha=0.5, n_iter=50, mode=None):\n",
      "    X = M[:,:-1]\n",
      "    y = M[:,-1]\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 10 iterations\n",
      "            if k%10==0: print \"Iter:\",k,\" Cost:\",J(M, beta)      \n",
      "        for i in range(m):\n",
      "            beta -= (alpha/m)*(np.dot(X[i],beta)-y[i])*X[i]\n",
      "    return beta\n",
      "\n",
      "#Implementation of Newton Rhapson approach\n",
      "def nr(J):\n",
      "    return\n",
      "\n",
      "def rescale(X,a,b):\n",
      "    #max and min vectors\n",
      "    maxv = np.max(X, axis=0)\n",
      "    minv = np.min(X, axis=0)\n",
      "    return (b-a)*X/(maxv-minv) + (a*maxv-b*minv)/(maxv-minv)\n",
      "\n",
      "def normalize(X):\n",
      "    #mean and standard deviation vectors\n",
      "    meanv = np.mean(X, axis=0)\n",
      "    stdv = np.std(X, axis=0)\n",
      "    return (X-meanv)/stdv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.arange(9).reshape((3,3)).astype(float)\n",
      "B = np.random.random((10,10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.concatenate((a,A),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([[ 1.,  0.,  1.,  2.],\n",
        "       [ 1.,  3.,  4.,  5.],\n",
        "       [ 1.,  6.,  7.,  8.]])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#working array\n",
      "wa = np.load(path1+'cereales-tr-0.npy')\n",
      "rescaled_wa = rescale(wa,0.,1.)\n",
      "beta1 = gd_batch(rescaled_wa, alpha=0.5, n_iter=200, mode='verbose')\n",
      "print 'beta:',beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter: 10  Cost: 2.16136156624\n",
        "Iter: 20  Cost: 1.46758846646\n",
        "Iter: 30  Cost: 1.10355081176\n",
        "Iter: 40  Cost: 0.896524938423\n",
        "Iter: 50  Cost: 0.769782117233\n",
        "Iter: 60  Cost: 0.687110170661\n",
        "Iter: 70  Cost: 0.630270631822\n",
        "Iter: 80  Cost: 0.58944371335\n",
        "Iter: 90  Cost: 0.558999863301\n",
        "Iter: 100  Cost: 0.535533170649\n",
        "Iter: 110  Cost: 0.516892756392\n",
        "Iter: 120  Cost: 0.50167523197\n",
        "Iter: 130  Cost: 0.488942065383\n",
        "Iter: 140  Cost: 0.47805342658\n",
        "Iter: 150  Cost: 0.468566091554\n",
        "Iter: 160  Cost: 0.460168552029\n",
        "Iter: 170  Cost: 0.45263873674\n",
        "Iter: 180  Cost: 0.445815966086\n",
        "Iter: 190  Cost: 0.439582102183\n",
        "beta: [-0.13761282  0.26752128 -0.23002782 -0.1540572   0.34881313  0.2834797\n",
        " -0.15375654  0.14559604 -0.16154358  0.09241099  0.19075178  0.42444575]\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta2 = gd_online(rescaled_wa, alpha=0.5, n_iter=200, mode='verbose')\n",
      "print 'beta:',beta2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter: 10  Cost: 2.177851008\n",
        "Iter: 20  Cost: 1.48025163788\n",
        "Iter: 30  Cost: 1.11231332729\n",
        "Iter: 40  Cost: 0.902572156003\n",
        "Iter: 50  Cost: 0.774092642865\n",
        "Iter: 60  Cost: 0.690307330543\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70  Cost: 0.632723541254\n",
        "Iter: 80  Cost: 0.591370948974\n",
        "Iter: 90  Cost: 0.560536545168\n",
        "Iter: 100  Cost: 0.536768466943\n",
        "Iter: 110  Cost: 0.517889596461\n",
        "Iter: 120  Cost: 0.502480508953\n",
        "Iter: 130  Cost: 0.489592046332\n",
        "Iter: 140  Cost: 0.478576805417\n",
        "Iter: 150  Cost: 0.468985872596\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 160  Cost: 0.460503325046\n",
        "Iter: 170  Cost: 0.452903606351\n",
        "Iter: 180  Cost: 0.446023261838\n",
        "Iter: 190  Cost: 0.439741934573\n",
        "beta: [-0.20630356  0.26036891 -0.2308226  -0.19084682  0.45804777  0.29496354\n",
        " -0.14758621  0.06599738 -0.17646091  0.1007918   0.23727576  0.49660913]\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}