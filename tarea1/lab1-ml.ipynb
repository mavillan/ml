{
 "metadata": {
  "name": "",
  "signature": "sha256:d48786ecac2de6b5843ffbf488bb38678a887b1dd9e22e6c72cd4b2a8875ef0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parte 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#notebook settings\n",
      "%matplotlib inline\n",
      "\n",
      "#import some useful libraries and utilities\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "#setting some paths\n",
      "path1='./cereales/'\n",
      "path2='./credit/'\n",
      "\n",
      "#parameters to try\n",
      "params = np.linspace(0.2,1.0,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#overall cost function\n",
      "def J(X, y, beta):\n",
      "    h = np.dot(X,beta)\n",
      "    return np.sum((h-y)**2)\n",
      "\n",
      "#Implementation of batch gradient descent\n",
      "def gd_batch(X, y, alpha=0.5, n_iter=500, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)\n",
      "        h = np.dot(X,beta)\n",
      "        dJ = np.dot(X.transpose(),h-y)\n",
      "        beta -= (alpha/m)*dJ\n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)\n",
      "    return beta\n",
      "\n",
      "#Implementation of online gradient descent\n",
      "def gd_online(X, y, alpha=0.5, n_iter=500, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)      \n",
      "        for i in range(m):\n",
      "            beta -= (alpha/m)*(np.dot(X[i],beta)-y[i])*X[i]\n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)        \n",
      "    return beta\n",
      "\n",
      "#Implementation of Newton Rhapson method\n",
      "def nr(X, y):\n",
      "    return\n",
      "\n",
      "#Implementation of weighted gradient descent\n",
      "def gd_weighted(X, y):\n",
      "    return\n",
      "\n",
      "def rescale(M,a,b):\n",
      "    \"\"\" Rescale features of M to [a,b] range \"\"\"\n",
      "    #max and min vectors\n",
      "    maxv = np.max(M, axis=0)\n",
      "    minv = np.min(M, axis=0)\n",
      "    return (b-a)*M/(maxv-minv) + (a*maxv-b*minv)/(maxv-minv)\n",
      "\n",
      "def normalize(M):\n",
      "    #mean and standard deviation vectors\n",
      "    meanv = np.mean(M, axis=0)\n",
      "    stdv = np.std(M, axis=0)\n",
      "    return (M-meanv)/stdv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#working array\n",
      "wa = np.load(path1+'cereales-tr-0.npy')\n",
      "rescaled_wa = rescale(wa,0.,1.)\n",
      "normalized_wa = normalize(wa)\n",
      "X = rescaled_wa[:,:-1]\n",
      "y = rescaled_wa[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta1 = gd_batch(X, y, alpha=0.5, n_iter=500, mode='verbose')\n",
      "print 'beta:',beta1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter: 100  Cost: 0.535533170649\n",
        "Iter: 200  Cost: 0.433848752371\n",
        "Iter: 300  Cost: 0.394214838927\n",
        "Iter: 400  Cost: 0.373000229573\n",
        "Iter: final  Cost: 0.361174289186\n",
        "beta: [-0.27722442  0.24140387 -0.18710511 -0.19526565  0.62842795  0.29594647\n",
        " -0.15844701 -0.08802599 -0.1868822   0.10954329  0.31140961  0.52442317]\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta2 = gd_online(X, y, alpha=0.5, n_iter=500, mode='verbose')\n",
      "print 'beta:',beta2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100  Cost: 0.536768466943\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200  Cost: 0.433969452824\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300  Cost: 0.39418888591\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 400  Cost: 0.372994798366\n",
        "Iter: final"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Cost: 0.361224333176\n",
        "beta: [-0.27631835  0.24392985 -0.18697424 -0.19409011  0.63116856  0.29575337\n",
        " -0.15781156 -0.09020163 -0.18622599  0.11040378  0.30989691  0.52540075]\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Find the best learning parameter for algorithm, between \n",
      "parameters in params using k-fold cross validation \"\"\"\n",
      "def find_best(X, y, algorithm, params, mode=None):\n",
      "    #creating kfold\n",
      "    m,n = X.shape\n",
      "    kf = KFold(m, n_folds=5)\n",
      "    tr_cost = list()\n",
      "    ts_cost = list()\n",
      "    \n",
      "    for param in params:\n",
      "        mean_tr_cost = 0\n",
      "        mean_ts_cost = 0\n",
      "        for tr_index,ts_index in kf:\n",
      "            X_train, X_test = X[tr_index], X[ts_index]\n",
      "            y_train, y_test = y[tr_index], y[ts_index]\n",
      "            beta = algorithm(X_train, y_train, alpha=param)\n",
      "            mean_tr_cost += J(X_train, y_train, beta)\n",
      "            mean_ts_cost += J(X_test, y_test, beta)\n",
      "        tr_cost.append(mean_tr_cost/5)\n",
      "        ts_cost.append(mean_ts_cost/5)\n",
      "    if mode=='verbose':\n",
      "        #print some info\n",
      "        print 'Mean training errors for each alpha:'\n",
      "        print tr_cost\n",
      "        print 'Mean testing errors for each alpha:'\n",
      "        print ts_cost\n",
      "    return params[np.argmin(np.array(ts_cost))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "find_best(X, y, gd_online, params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(20):\n",
      "    tr_file = path1+'cereales-tr-{0}.npy'.format(i)\n",
      "    ts_file = path1+'cereales-ts-{0}.npy'.format(i)\n",
      "    tr_data = np.load(tr_file)\n",
      "    ts_data = np.load(ts_file)\n",
      "    X_tr = rescale(tr_data[:,:-1], 0., 1.)\n",
      "    y_tr = tr_data[:,-1]\n",
      "    X_ts = rescale(ts_data[:,:-1], 0., 1.)\n",
      "    y_ts = ts_data[:,-1]\n",
      "    alpha = find_best(X_tr, y_tr, gd_batch, params)\n",
      "    beta = gd_batch(X_tr, y_tr, alpha)\n",
      "    print 'Best alpha:',alpha,'Training error:',J(X_tr,y_tr,beta),'Testing error:',J(X_ts,y_ts,beta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best alpha: 0.8 training error: 4119.10617737 testing error: 5026.06819352\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3988.90354004 testing error: 4650.92412148\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 5562.5560813 testing error: 7802.88204023\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 5314.42186631 testing error: 8172.9302819\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3642.48445979 testing error: 3549.21710496\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4 training error: 3295.44864751 testing error: 4745.66636134\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3926.05877497 testing error: 10240.8375572\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6 training error: 3788.40117917 testing error: 3751.95588142\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 4278.47327833 testing error: 4259.09036329\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6 training error: 3996.1175349 testing error: 17840.679773\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4 training error: 4276.64312906 testing error: 4910.99378626\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6 training error: 5018.00996138 testing error: 4689.74906703\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6 training error: 3946.15329967 testing error: 7212.83591035\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3966.23353656 testing error: 11692.765469\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3278.8169761 testing error: 10325.4770665\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3398.39854265 testing error: 4757.58969506\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 3487.08137165 testing error: 18912.5765888\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 5146.44647084 testing error: 3636.11198138\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8 training error: 4749.7242021 testing error: 13516.7106218\n",
        "Best alpha:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6 training error: 3576.29210505 testing error: 5813.25565015\n"
       ]
      }
     ],
     "prompt_number": 196
    }
   ],
   "metadata": {}
  }
 ]
}