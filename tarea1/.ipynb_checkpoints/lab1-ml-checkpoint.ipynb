{
 "metadata": {
  "name": "",
  "signature": "sha256:d48786ecac2de6b5843ffbf488bb38678a887b1dd9e22e6c72cd4b2a8875ef0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parte 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#notebook settings\n",
      "%matplotlib inline\n",
      "\n",
      "#import some useful libraries and utilities\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "#setting some paths\n",
      "path1='./cereales/'\n",
      "path2='./credit/'\n",
      "\n",
      "#parameters to try\n",
      "params = np.array([0.2, 0.4, 0.6, 0.8, 1.0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#overall cost function\n",
      "def J(X, y, beta):\n",
      "    h = np.dot(X,beta)\n",
      "    return np.sum((h-y)**2)\n",
      "\n",
      "#Implementation of batch gradient descent\n",
      "def gd_batch(X, y, alpha=0.5, n_iter=1000, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)\n",
      "        h = np.dot(X,beta)\n",
      "        dJ = np.dot(X.transpose(),h-y)\n",
      "        beta -= (alpha/m)*dJ\n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)\n",
      "    return beta\n",
      "\n",
      "#Implementation of online gradient descent\n",
      "def gd_online(X, y, alpha=0.5, n_iter=1000, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)      \n",
      "        for i in range(m):\n",
      "            beta -= (alpha/m)*(np.dot(X[i],beta)-y[i])*X[i]\n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)        \n",
      "    return beta\n",
      "\n",
      "#Implementation of Newton Rhapson method\n",
      "def nr(X, y):\n",
      "    return\n",
      "\n",
      "#Implementation of weighted gradient descent\n",
      "def gd_weighted(X, y):\n",
      "    return\n",
      "\n",
      "def rescale(M,a,b):\n",
      "    \"\"\" Rescale features of M to [a,b] range \"\"\"\n",
      "    #max and min vectors\n",
      "    maxv = np.max(M, axis=0)\n",
      "    minv = np.min(M, axis=0)\n",
      "    return (b-a)*M/(maxv-minv) + (a*maxv-b*minv)/(maxv-minv)\n",
      "\n",
      "def normalize(M):\n",
      "    #mean and standard deviation vectors\n",
      "    meanv = np.mean(M, axis=0)\n",
      "    stdv = np.std(M, axis=0)\n",
      "    return (M-meanv)/stdv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#working array\n",
      "wa = np.load(path1+'cereales-tr-0.npy')\n",
      "rescaled_wa = rescale(wa,0.,1.)\n",
      "normalized_wa = normalize(wa)\n",
      "X = rescaled_wa[:,:-1]\n",
      "y = rescaled_wa[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta1 = gd_batch(X, y, alpha=0.5, n_iter=1000, mode='verbose')\n",
      "print 'beta:',beta1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter: 100  Cost: 0.535533170649\n",
        "Iter: 200  Cost: 0.433848752371\n",
        "Iter: 300  Cost: 0.394214838927\n",
        "Iter: 400  Cost: 0.373000229573\n",
        "Iter: 500  Cost: 0.361174289186\n",
        "Iter: 600  Cost: 0.354460958991\n",
        "Iter: 700  Cost: 0.350597550444\n",
        "Iter: 800  Cost: 0.348349448567\n",
        "Iter: 900  Cost: 0.347029253749\n",
        "Iter: final  Cost: 0.346248026688\n",
        "beta: [-0.29076217  0.23597586 -0.1720192  -0.19521529  0.72873049  0.28960355\n",
        " -0.17004585 -0.1843903  -0.19542012  0.11690547  0.35025307  0.52746198]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta2 = gd_online(X, y, alpha=0.5, n_iter=1000, mode='verbose')\n",
      "print 'beta:',beta2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100  Cost: 0.536768466943\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200  Cost: 0.433969452824\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300  Cost: 0.39418888591\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 400  Cost: 0.372994798366\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 500  Cost: 0.361224333176\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 600  Cost: 0.354565488892\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 700  Cost: 0.350745833783\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 800  Cost: 0.348529948221\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 900  Cost: 0.347232384351\n",
        "Iter: final"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Cost: 0.346466607386\n",
        "beta: [-0.28970793  0.23776604 -0.17183418 -0.19364941  0.73105399  0.28863557\n",
        " -0.1699008  -0.18600034 -0.19496269  0.11747285  0.348319    0.52927477]\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(75, n_folds=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sklearn.cross_validation.KFold(n=75, n_folds=5)\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for alpha in params:\n",
      "    for tr_index,ts_index in kf:\n",
      "        X_train, X_test = \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}