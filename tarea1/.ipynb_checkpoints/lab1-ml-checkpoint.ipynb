{
 "metadata": {
  "name": "",
  "signature": "sha256:d48786ecac2de6b5843ffbf488bb38678a887b1dd9e22e6c72cd4b2a8875ef0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parte 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#notebook settings\n",
      "%matplotlib inline\n",
      "\n",
      "#import some useful libraries and utilities\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "#setting some paths\n",
      "path1='./cereales/'\n",
      "path2='./credit/'\n",
      "\n",
      "#parameters to try\n",
      "params = np.linspace(0.2,1.0,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#overall cost function\n",
      "def J(X, y, beta):\n",
      "    h = np.dot(X,beta)\n",
      "    return np.sum((h-y)**2)\n",
      "\n",
      "#Implementation of batch gradient descent\n",
      "def gd_batch(X, y, alpha=0.5, eps=10e-5, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)\n",
      "        J0 = J(X,y,beta)\n",
      "        h = np.dot(X,beta)\n",
      "        dJ = np.dot(X.transpose(),h-y)\n",
      "        beta -= (alpha/m)*dJ\n",
      "        if (J(X,y,beta)-J0)/J0 < eps: break \n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)\n",
      "    return beta\n",
      "\n",
      "#Implementation of online gradient descent\n",
      "def gd_online(X, y, alpha=0.5, eps=10e-5, mode=None):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    for k in range(n_iter):\n",
      "        if mode=='verbose':\n",
      "            #print each 100 iterations\n",
      "            if k%100==0: print \"Iter:\", k,\" Cost:\", J(X,y,beta)      \n",
      "        for i in range(m):\n",
      "            beta -= (alpha/m)*(np.dot(X[i],beta)-y[i])*X[i]\n",
      "    if mode=='verbose':\n",
      "        #final result\n",
      "        print \"Iter: final\",\" Cost:\", J(X,y,beta)        \n",
      "    return beta\n",
      "\n",
      "#Implementation of Newton-Raphson method for linear regression\n",
      "def newton_raphson_linear(X, y, eps=10e-5):\n",
      "    m,n = X.shape\n",
      "    beta = np.zeros(n)\n",
      "    #computing the inverse of Hessian matrix \n",
      "    Hinv = np.linalg.inv(np.dot(X.transpose(),X))\n",
      "    for k in range(n_iter):\n",
      "        h = np.dot(X,beta)\n",
      "        dJ = np.dot(X.transpose(),h-y)\n",
      "        beta -= np.dot(Hinv, dJ)\n",
      "    return beta\n",
      "\n",
      "#Implementation of weighted gradient descent\n",
      "def gd_weighted(X, y):\n",
      "    return\n",
      "\n",
      "#Implementation of Newton-Raphson method for logistic regression\n",
      "def newton_raphson_logistic(X, y, n_iter=50):\n",
      "    return\n",
      "\n",
      "def rescale(M,a,b):\n",
      "    \"\"\" Rescale features of M to [a,b] range \"\"\"\n",
      "    #max and min vectors\n",
      "    maxv = np.max(M, axis=0)\n",
      "    minv = np.min(M, axis=0)\n",
      "    return (b-a)*M/(maxv-minv) + (a*maxv-b*minv)/(maxv-minv)\n",
      "\n",
      "def normalize(M):\n",
      "    #mean and standard deviation vectors\n",
      "    meanv = np.mean(M, axis=0)\n",
      "    stdv = np.std(M, axis=0)\n",
      "    return (M-meanv)/stdv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#working array\n",
      "wa = np.load(path1+'cereales-tr-0.npy')\n",
      "rescaled_wa = rescale(wa,0.,1.)\n",
      "normalized_wa = normalize(wa)\n",
      "X = rescaled_wa[:,:-1]\n",
      "y = rescaled_wa[:,-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta1 = gd_batch(X, y, alpha=0.5, n_iter=500, mode='verbose')\n",
      "print 'beta:',beta1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter: 100  Cost: 0.535533170649\n",
        "Iter: 200  Cost: 0.433848752371\n",
        "Iter: 300  Cost: 0.394214838927\n",
        "Iter: 400  Cost: 0.373000229573\n",
        "Iter: final  Cost: 0.361174289186\n",
        "beta: [-0.27722442  0.24140387 -0.18710511 -0.19526565  0.62842795  0.29594647\n",
        " -0.15844701 -0.08802599 -0.1868822   0.10954329  0.31140961  0.52442317]\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta2 = gd_online(X, y, alpha=0.5, n_iter=500, mode='verbose')\n",
      "print 'beta:',beta2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter: 0  Cost: 11.94902456\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100  Cost: 0.536768466943\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200  Cost: 0.433969452824\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300  Cost: 0.39418888591\n",
        "Iter:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 400  Cost: 0.372994798366\n",
        "Iter: final"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Cost: 0.361224333176\n",
        "beta: [-0.27631835  0.24392985 -0.18697424 -0.19409011  0.63116856  0.29575337\n",
        " -0.15781156 -0.09020163 -0.18622599  0.11040378  0.30989691  0.52540075]\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Find the best learning parameter for algorithm, between \n",
      "parameters in params using k-fold cross validation \"\"\"\n",
      "def find_best(X, y, algorithm, params, mode=None):\n",
      "    #creating kfold\n",
      "    m,n = X.shape\n",
      "    kf = KFold(m, n_folds=5)\n",
      "    tr_cost = list()\n",
      "    ts_cost = list()\n",
      "    \n",
      "    for param in params:\n",
      "        mean_tr_cost = 0\n",
      "        mean_ts_cost = 0\n",
      "        for tr_index,ts_index in kf:\n",
      "            X_train, X_test = X[tr_index], X[ts_index]\n",
      "            y_train, y_test = y[tr_index], y[ts_index]\n",
      "            beta = algorithm(X_train, y_train, alpha=param)\n",
      "            mean_tr_cost += J(X_train, y_train, beta)\n",
      "            mean_ts_cost += J(X_test, y_test, beta)\n",
      "        tr_cost.append(mean_tr_cost/5)\n",
      "        ts_cost.append(mean_ts_cost/5)\n",
      "    if mode=='verbose':\n",
      "        #print some info\n",
      "        print 'Mean training errors for each alpha:'\n",
      "        print tr_cost\n",
      "        print 'Mean testing errors for each alpha:'\n",
      "        print ts_cost\n",
      "    return params[np.argmin(np.array(ts_cost))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "find_best(X, y, gd_online, params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "for i in range(20):\n",
      "    tr_file = path1+'cereales-tr-{0}.npy'.format(i)\n",
      "    ts_file = path1+'cereales-ts-{0}.npy'.format(i)\n",
      "    tr_data = np.load(tr_file)\n",
      "    ts_data = np.load(ts_file)\n",
      "    X_tr = rescale(tr_data[:,:-1], 0., 1.)\n",
      "    y_tr = tr_data[:,-1]\n",
      "    X_ts = rescale(ts_data[:,:-1], 0., 1.)\n",
      "    y_ts = ts_data[:,-1]\n",
      "    alpha = find_best(X_tr, y_tr, gd_batch, params)\n",
      "    beta = gd_batch(X_tr, y_tr, alpha)\n",
      "    print 'Best alpha:',alpha,'Training error:',J(X_tr,y_tr,beta),'Testing error:',J(X_ts,y_ts,beta)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newton_raphson_linear(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([-0.28477401,  0.23382422, -0.1711402 , -0.19611558,  0.766077  ,\n",
        "        0.28185174, -0.17850135, -0.22100888, -0.19930546,  0.11996579,\n",
        "        0.36355978,  0.52893807])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gd_batch(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([-0.27722442,  0.24140387, -0.18710511, -0.19526565,  0.62842795,\n",
        "        0.29594647, -0.15844701, -0.08802599, -0.1868822 ,  0.10954329,\n",
        "        0.31140961,  0.52442317])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}